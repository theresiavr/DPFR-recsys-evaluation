{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "list_dataset = [\"Lastfm\", \"Amazon-lb\", \"QK-video\", \"Jester\", \"ML-10M\", \"ML-20M\"]\n",
    "\n",
    "path_estimate = \"../pareto/estimate\"\n",
    "path_full = \"../pareto/result_combined\"\n",
    "\n",
    "time_file_estimate = [f for f in os.listdir(path_estimate) if \"time\" in f]\n",
    "time_file_full = [f for f in os.listdir(path_full) if \"time\" in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full PF and oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = {}\n",
    "for f in time_file_full:\n",
    "    name = f.replace(\"time_pareto_new_\",\"\").split(\"_\")[0]\n",
    "    if name not in result:\n",
    "        result[name] = {}\n",
    "    thetime = pd.read_pickle(f\"{path_full}/{f}\")\n",
    "    if \"oracle2fair\" in f:\n",
    "        result[name][\"oracle2fair\"] = thetime\n",
    "    else:\n",
    "        result[name][\"oracle\"] = thetime\n",
    "\n",
    "df_full = pd.DataFrame(result)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_result = {}\n",
    "for f in time_file_estimate:\n",
    "    splitted = f.replace(\"time_pareto_new_\",\"\").split(\"_\")\n",
    "    name, num_pt_estimate = splitted[0], int(splitted[3].replace(\"with\",\"\"))\n",
    "    if name not in est_result:\n",
    "        est_result[name] = {}\n",
    "    if \"oracle2fair\" in f:\n",
    "        est_result[name][f\"with{num_pt_estimate+2}\"] = pd.read_pickle(f\"{path_estimate}/{f}\")\n",
    "\n",
    "       \n",
    "df_est = pd.DataFrame(est_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.loc[\"PF\"] = df_full.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df_full.append(df_est.loc[[\"with3\", \"with6\", \"with12\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[\"Est.~PF (12)\"] = final_df.loc[\"oracle\"] + final_df.loc[\"with12\"]\n",
    "final_df.loc[\"Est.~PF (6)\"] = final_df.loc[\"oracle\"] + final_df.loc[\"with6\"]\n",
    "final_df.loc[\"Est.~PF (3)\"] = final_df.loc[\"oracle\"] + final_df.loc[\"with3\"]\n",
    "final_df = final_df.loc[[\"PF\", \"Est.~PF (12)\", \"Est.~PF (6)\",  \"Est.~PF (3)\"], list_dataset]\n",
    "\n",
    "#TIME IN MINUTES\n",
    "final_df = final_df / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.applymap(lambda x: '{0:.2f}'.format(x)).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MME - base\n",
    "\n",
    "load from timing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MME_base_files = list(filter(lambda x: \"time\" in x, os.listdir(\"../eval/MME\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "MME_base_result = {}\n",
    "for f in MME_base_files:\n",
    "    _, _, data, model = f.replace(\".pickle\",\"\").split(\"_\")\n",
    "    \n",
    "    if data not in MME_base_result:\n",
    "        MME_base_result[data] = {}\n",
    "    \n",
    "    \n",
    "    MME_base_result[data][model] = pd.read_pickle(f\"../eval/MME/{f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MME = pd.DataFrame(MME_base_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MME - rerank\n",
    "\n",
    "Have to parse from log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MME_rerank = \"../reranking/MME/log\"\n",
    "MME_rerank_files = list(filter(lambda x: \"log\" in x, os.listdir(path_MME_rerank)))\n",
    "MME_rerank_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "MME_rerank_result = {}\n",
    "for f in MME_rerank_files:\n",
    "    _, _, data, model, rerank = f\\\n",
    "                                    .replace(\".txt\",\"\")\\\n",
    "                                    .replace(\"-subset-0.05\",\"\")\\\n",
    "                                    .split(\"_\")\n",
    "    with open(f\"{path_MME_rerank}/{f}\",\"r\") as thefile:\n",
    "        line_containing_time = thefile.readlines()[3]\n",
    "        clean_time = line_containing_time.split(\" \")[4].strip(\"\\n\")\n",
    "        clean_time = float(clean_time)\n",
    "\n",
    "    if data not in MME_rerank_result:\n",
    "        MME_rerank_result[data] = {}\n",
    "    \n",
    "    MME_rerank_result[data][f\"{model}_{rerank}\"] = clean_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MME_rerank = pd.DataFrame(MME_rerank_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine MME base and rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb_MME = df_MME.append(df_MME_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[\"Total - MME\"] = df_comb_MME.sum() / 60\n",
    "final_df.loc[\"Avg - MME\"] = df_comb_MME.mean() / 60\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other joint measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_results(path, rerank=False):\n",
    "    joint_base_files = list(filter(lambda x: \"time\" in x, os.listdir(path)))\n",
    "    joint_base_result = {}\n",
    "\n",
    "    for f in joint_base_files:\n",
    "        if not rerank:\n",
    "            _, measure, data, model = f.replace(\".pickle\",\"\").split(\"_\")\n",
    "        elif rerank:\n",
    "            _, measure, data, model, rerank, _, _= f\\\n",
    "                                                .replace(\".pickle\",\"\")\\\n",
    "                                                .replace(\"-subset-0.05\",\"\")\\\n",
    "                                                .split(\"_\")\n",
    "            model = f\"{model}_{rerank}\"\n",
    "\n",
    "        if data not in joint_base_result:\n",
    "            joint_base_result[data] = {}\n",
    "\n",
    "        if measure not in joint_base_result[data]:\n",
    "            joint_base_result[data][measure] = {}\n",
    "        \n",
    "        joint_base_result[data][measure][model] = pd.read_pickle(f\"{path}/{f}\")\n",
    "\n",
    "    df_joint = pd.DataFrame(joint_base_result)\n",
    "\n",
    "    return df_joint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_joint = get_joint_results(\"../eval/joint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_joint_rerank = \"../reranking/joint/\"\n",
    "rerank_joint = get_joint_results(path_joint_rerank, rerank=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_joint = rerank_joint.rename(index={\"IAArerank\":\"IAA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(dict1, dict2):\n",
    "    res = {**dict1, **dict2}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint = base_joint.append(rerank_joint)\n",
    "df_joint = df_joint.groupby(df_joint.index).agg(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint = df_joint.applymap(lambda x: merge(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint.applymap(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint_avg = df_joint.applymap(lambda x: sum(x.values())/len(x))\n",
    "df_joint_sum = df_joint.applymap(lambda x: sum(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint_avg = df_joint_avg.rename(index={\"AIF\":\"AI-F\",\"IIF\":\"II-F\"})\n",
    "df_joint_avg = df_joint_avg / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint_avg.index = \"Avg - \" + df_joint_avg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joint_sum = df_joint_sum.rename(index={\"AIF\":\"AI-F\",\"IIF\":\"II-F\"})\n",
    "df_joint_sum = df_joint_sum / 60\n",
    "df_joint_sum.index = \"Total - \" + df_joint_sum.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"IBO\", \"MME\", \"IAA\", \"II-F\", \"AI-F\"]\n",
    "avg_names = [f\"Avg - {name}\" for name in names]\n",
    "sum_names = [f\"Total - {name}\" for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.append(df_joint_avg).append(df_joint_sum)\n",
    "final_df = final_df.loc[[\"PF\", \"Est.~PF (12)\", \"Est.~PF (6)\"] + avg_names + sum_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex table from `final_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_rounded = final_df.round(2)\n",
    "final_df_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_rounded[final_df_rounded == 0]  = '<0.3s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df_rounded.round(2).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare estimated PF to PF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "efficiency_table = {}\n",
    "base_path = \"../pareto\"\n",
    "full_path = \"/result_combined\"\n",
    "est_path = \"/estimate\"\n",
    "\n",
    "list_dataset = [\n",
    "                \"Lastfm\", \n",
    "                \"Amazon-lb\", \"QK-video\", \n",
    "                \"Jester\", \n",
    "                \"ML-10M\", \n",
    "                \"ML-20M\"\n",
    "                ]\n",
    "\n",
    "should_decrease_measures = [\n",
    "                            'P@10', 'MAP@10', 'R@10', 'NDCG@10', 'Gini_our@10',]\n",
    "should_increase_measures = [\n",
    "                            'Jain_our@10', \n",
    "                            'Ent_our@10', \n",
    "                            ]\n",
    "\n",
    "def check_monotonic(x:pd.Series):\n",
    "    if x.name in should_decrease_measures:\n",
    "        return x.is_monotonic_decreasing\n",
    "    elif x.name in should_increase_measures:\n",
    "        return x.is_monotonic_increasing\n",
    "\n",
    "for dataset in list_dataset:\n",
    "    efficiency_table[dataset] = {}\n",
    "    real = pd.read_pickle(f\"{base_path}{full_path}/pareto_new_{dataset}_oraclefair_at10.pickle\")\n",
    "    #here we dont drop duplicates\n",
    "    # we take all the points in the PF including those that may be duplicates (because the duplicates may be unique per measure pair)\n",
    "    efficiency_table[dataset][\"\\# points in full PF\"] = int(real.shape[0]) \n",
    "    efficiency_table[dataset][\"\\% points in estimated PF\"] = []\n",
    "\n",
    "    for numpt in range(1,11):\n",
    "        # print(numpt)\n",
    "        est = pd.read_pickle(f\"{base_path}{est_path}/estimate_new_{dataset}_oraclefair_at10_with{numpt}.pickle\")\n",
    "        \n",
    "    #check if all points in est are in real\n",
    "    #thanks to https://stackoverflow.com/questions/49530918/check-if-pandas-dataframe-is-subset-of-other-dataframe\n",
    "        try:\n",
    "            assert len(est.merge(real, how=\"inner\").drop_duplicates()) == len(est.drop_duplicates())\n",
    "            assert len(est) == (numpt+2)\n",
    "        except:\n",
    "            print(dataset, numpt, len(est))\n",
    "\n",
    "        tocheck = real.loc[:,(real.columns.isin(should_decrease_measures)|real.columns.isin(should_increase_measures))]\n",
    "\n",
    "        try:\n",
    "            assert all(tocheck.apply(lambda x: check_monotonic(x)))\n",
    "        except:\n",
    "            print(f\"One or more columns are not monotonic in {dataset}\")\n",
    "            display(tocheck.apply(lambda x: check_monotonic(x)))\n",
    "    \n",
    "        pctg_est_point_out_of_full = est.shape[0] / real.shape[0] * 100\n",
    "\n",
    "        efficiency_table[dataset][\"\\% points in estimated PF\"].append(pctg_est_point_out_of_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_efficiency = pd.DataFrame(efficiency_table).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(df_efficiency[\"\\\\% points in estimated PF\"].apply(min).apply(lambda x: '{0:.2f}'.format(x))).T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(df_efficiency[\"\\\\% points in estimated PF\"].apply(max).round(2).apply(lambda x: '{0:.2f}'.format(x))).T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(df_efficiency[\"\\\\% points in estimated PF\"].apply(lambda x: x[3]).round(2).apply(lambda x: '{0:.2f}'.format(x))).T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(list_of_val, rounding=3):\n",
    "    min_val = min(list_of_val)\n",
    "    max_val = max(list_of_val)\n",
    "    return f\"{'{0:.3f}'.format(round(min_val,rounding))}--{round(max_val,rounding)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_efficiency[\"\\\\% points in estimated PF\"] = df_efficiency[\"\\\\% points in estimated PF\"].apply(get_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_est = {}\n",
    "path_integral_point_full = pd.read_pickle(\"efficiency/path_integral_point_full.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_path_integral_point(path_integral_point):\n",
    "    path_integral_point = path_integral_point.loc[path_integral_point.index.str.contains(\"our\")]\n",
    "    path_integral_point = path_integral_point.loc[path_integral_point.index.str.contains(\"Jain|Ent|Gini\")]\n",
    "    path_integral_point = path_integral_point.drop(columns=[\"HR@10\",\"MRR@10\"])\n",
    "    return path_integral_point\n",
    "\n",
    "def compute_avg_delta_position(path_integral_full_d, path_integral_est_d):\n",
    "    diff = path_integral_full_d - path_integral_est_d\n",
    "    final_res = diff\\\n",
    "                    .applymap(lambda x: np.power(x, 2))\\\n",
    "                    .applymap(sum)\\\n",
    "                    .applymap(np.sqrt)\\\n",
    "                    .stack()\\\n",
    "                    .dropna()\\\n",
    "                    .mean()\n",
    "    \n",
    "    return final_res\n",
    "\n",
    "for data in list_dataset:\n",
    "    path_integral_full_data = filter_path_integral_point(path_integral_point_full[data])\n",
    "    result_est[data] = []\n",
    "    for numpt in range(1,11):\n",
    "        path_integral_point_est = pd.read_pickle(f\"efficiency/path_integral_point_with{numpt}.pickle\")\n",
    "        path_integral_est_data = filter_path_integral_point(path_integral_point_est[data])\n",
    "\n",
    "        euclid_distance = compute_avg_delta_position(path_integral_full_data, path_integral_est_data)\n",
    "\n",
    "        result_est[data].append(euclid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_6 = {}\n",
    "dist_12 = {}\n",
    "dist_3 = {}\n",
    "for k, v in result_est.items():\n",
    "    dist_3[k] = v[0]\n",
    "     #index 3 and 9, because numpoint is 4 and 10 , numpoint in pareto = 6 and 12\n",
    "    dist_6[k] = v[3]\n",
    "    dist_12[k] = v[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_dist_6 = pd.Series(dist_6)\n",
    "row_dist_12 = pd.Series(dist_12)\n",
    "row_dist_3 = pd.Series(dist_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame()\n",
    "newdf[\"dist3\"] = row_dist_3\n",
    "newdf[\"dist6\"] = row_dist_6\n",
    "newdf[\"dist12\"] = row_dist_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newdf.T.applymap(lambda x: '{0:.2f}'.format(x)).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corr table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_distance_dict_full = pd.read_pickle(f\"efficiency/model_distance_dict_full.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_based_rank_for_corr(model_distance_dict, data):\n",
    "    rank_based_on_distance = model_distance_dict[data].unstack().reset_index()\n",
    "    rank_based_on_distance.columns = [\"rel\",\"fair\",\"models\"]\n",
    "    rank_based_on_distance = rank_based_on_distance.loc[rank_based_on_distance.rel.str.contains(\"^P|^R|NDCG|MAP\")]\n",
    "    rank_based_on_distance = rank_based_on_distance.loc[rank_based_on_distance.fair.str.contains(\"Jain|Gini|Ent\")]\n",
    "    rank_based_on_distance = rank_based_on_distance.loc[rank_based_on_distance.fair.str.contains(\"our\")]\n",
    "    rank_based_on_distance = rank_based_on_distance.loc[rank_based_on_distance.models.apply(lambda x: x[1]).dropna().index]\n",
    "    rank_based_on_distance[\"col_name\"] = rank_based_on_distance.rel + \"-\" + rank_based_on_distance.fair\n",
    "    rank_based_on_distance = rank_based_on_distance[[\"col_name\",\"models\"]].T\n",
    "    rank_based_on_distance.columns = rank_based_on_distance.loc[\"col_name\"]\n",
    "    rank_based_on_distance = rank_based_on_distance.iloc[1].T\n",
    "    \n",
    "    dict_rank_based_on_distance = {}\n",
    "\n",
    "    for row, item in pd.DataFrame(rank_based_on_distance).iterrows():\n",
    "        the_tup = item[0]\n",
    "        model_name = the_tup[0]\n",
    "        scores = the_tup[1]\n",
    "        dict_rank_based_on_distance[row] = dict((key,val) for key,val in zip(model_name, scores))\n",
    "\n",
    "\n",
    "    for_corr = pd.DataFrame(dict_rank_based_on_distance).T.applymap(lambda x: -x)\n",
    "\n",
    "    return for_corr\n",
    "\n",
    "\n",
    "def compare_full_est(model_distance_dict_full, model_distance_dict_est):\n",
    "\n",
    "    forplot = pd.DataFrame()\n",
    "\n",
    "    for data in list_dataset:\n",
    "        for_corr_full = distance_based_rank_for_corr(model_distance_dict_full, data)\n",
    "        for_corr_est = distance_based_rank_for_corr(model_distance_dict_est, data)\n",
    "\n",
    "        for_corr_full.index = for_corr_full.index.str.replace(\"_our@10\", \"\") + \"-full\"\n",
    "        for_corr_est.index = for_corr_est.index.str.replace(\"_our@10\", \"\") + \"-est\"\n",
    "\n",
    "        final_corr = pd.concat([for_corr_full, for_corr_est])\n",
    "        \n",
    "        final_corr = final_corr.T\\\n",
    "                        .reset_index(drop=True)\\\n",
    "                        .applymap(float)\\\n",
    "                        .corr(method=\"kendall\")\\\n",
    "                        .round(2)\n",
    "        \n",
    "        filtered_final_corr = final_corr.loc[final_corr.index[final_corr.index.str.contains(\"full\")], final_corr.columns[final_corr.columns.str.contains(\"est\")]]\n",
    "\n",
    "        forplot[data] = pd.Series(np.diag(filtered_final_corr), index=[filtered_final_corr.index.str.replace(\"-full\",\"\")]) \n",
    "    \n",
    "\n",
    "    return forplot\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for numpt in range(1, 11):\n",
    "    model_distance_dict_est = pd.read_pickle(f\"efficiency/model_distance_dict_with{numpt}.pickle\")\n",
    "    fullvsest = compare_full_est(model_distance_dict_full, model_distance_dict_est)\n",
    "\n",
    "    result_dict[numpt+2] = fullvsest.min().apply(lambda x: '{0:.2f}'.format(x)) +  \"--\" + fullvsest.max().apply(lambda x: '{0:.2f}'.format(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appendix\n",
    "print(pd.DataFrame(result_dict).T.to_latex()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "\n",
    "for numpt in range(1, 11):\n",
    "    model_distance_dict_est = pd.read_pickle(f\"efficiency/model_distance_dict_with{numpt}.pickle\")\n",
    "    fullvsest = compare_full_est(model_distance_dict_full, model_distance_dict_est)\n",
    "\n",
    "    result_dict[numpt+2] = fullvsest.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main paper\n",
    "print(pd.DataFrame(result_dict).T.to_latex()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jointeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
